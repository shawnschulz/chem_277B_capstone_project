{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This notebook is to optimize hyperparameters for LSTM Model Classification using Randomized Search'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"This notebook is to optimize hyperparameters for LSTM Model Classification using Randomized Search\"\"\"\n",
    "\n",
    "# seperated by npast_timesteps to make preprocessing easier (tried doing it inside the wrapper and ran into many shape issues) \n",
    "# kernal crashed when I tried to do it all in one for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 12:21:20.690240: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-12 12:21:20.691813: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-12 12:21:20.696809: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-12 12:21:20.710949: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1734034880.728099  112786 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1734034880.732395  112786 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-12 12:21:20.751438: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# imports \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nrsim_lstm import NRSIM_LSTM as lstm\n",
    "from Archive import utils277b as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing and Set Parameters for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>pH</th>\n",
       "      <th>Hydrogen</th>\n",
       "      <th>Total Gas</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>Radioactivity</th>\n",
       "      <th>Power</th>\n",
       "      <th>Reactor Safety</th>\n",
       "      <th>Injection of Air</th>\n",
       "      <th>Injection of Air Degree</th>\n",
       "      <th>Resin Overheat</th>\n",
       "      <th>Resin Overheat Degree</th>\n",
       "      <th>Fuel Element Failure</th>\n",
       "      <th>Fuel Element Failure Degree</th>\n",
       "      <th>Chemical Addition</th>\n",
       "      <th>Vent Gas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11.000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>2100.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10.998</td>\n",
       "      <td>50.112998</td>\n",
       "      <td>60.112998</td>\n",
       "      <td>500.732703</td>\n",
       "      <td>2104.971916</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10.996</td>\n",
       "      <td>50.225941</td>\n",
       "      <td>60.225941</td>\n",
       "      <td>501.463398</td>\n",
       "      <td>2109.930204</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10.994</td>\n",
       "      <td>50.338517</td>\n",
       "      <td>60.338517</td>\n",
       "      <td>502.190083</td>\n",
       "      <td>2114.861274</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10.992</td>\n",
       "      <td>50.450414</td>\n",
       "      <td>60.450414</td>\n",
       "      <td>502.910764</td>\n",
       "      <td>2119.751611</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time      pH   Hydrogen  Total Gas  Temperature     Pressure  \\\n",
       "0     0  11.000  50.000000  60.000000   500.000000  2100.000000   \n",
       "1     1  10.998  50.112998  60.112998   500.732703  2104.971916   \n",
       "2     2  10.996  50.225941  60.225941   501.463398  2109.930204   \n",
       "3     3  10.994  50.338517  60.338517   502.190083  2114.861274   \n",
       "4     4  10.992  50.450414  60.450414   502.910764  2119.751611   \n",
       "\n",
       "   Radioactivity  Power  Reactor Safety Injection of Air  \\\n",
       "0           10.0  100.0               0              NaN   \n",
       "1           10.0  100.0               0              NaN   \n",
       "2           10.0  100.0               0              NaN   \n",
       "3           10.0  100.0               0              NaN   \n",
       "4           10.0  100.0               0              NaN   \n",
       "\n",
       "  Injection of Air Degree Resin Overheat Resin Overheat Degree  \\\n",
       "0                     NaN            NaN                   NaN   \n",
       "1                     NaN            NaN                   NaN   \n",
       "2                     NaN            NaN                   NaN   \n",
       "3                     NaN            NaN                   NaN   \n",
       "4                     NaN            NaN                   NaN   \n",
       "\n",
       "  Fuel Element Failure Fuel Element Failure Degree  Chemical Addition  \\\n",
       "0                  NaN                         NaN              False   \n",
       "1                  NaN                         NaN              False   \n",
       "2                  NaN                         NaN              False   \n",
       "3                  NaN                         NaN              False   \n",
       "4                  NaN                         NaN              False   \n",
       "\n",
       "   Vent Gas  \n",
       "0     False  \n",
       "1     False  \n",
       "2     False  \n",
       "3     False  \n",
       "4     False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in data\n",
    "data = pd.read_csv(\"data/Sim_all_casualties.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_95616/1598807462.py:8: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data = data.fillna(False)\n"
     ]
    }
   ],
   "source": [
    "numerical = ['Time', 'pH', 'Hydrogen', 'Total Gas', 'Temperature', 'Pressure','Radioactivity', 'Power']\n",
    "categorical = ['Reactor Safety', 'Injection of Air', 'Injection of Air Degree', \n",
    "               'Resin Overheat', 'Resin Overheat Degree', 'Fuel Element Failure', \n",
    "               'Fuel Element Failure Degree', 'Chemical Addition', 'Vent Gas']\n",
    "\n",
    "\n",
    "# In case there are NaN values\n",
    "data = data.fillna(False)\n",
    "data[categorical] = data[categorical].astype(int) # set categorical as integer\n",
    "\n",
    "# make sure no NaN values\n",
    "unique_values = data.apply(pd.Series.unique)\n",
    "# print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training matrices\n",
    "X = np.array(data[numerical].drop(columns=['Time']))\n",
    "Y = np.array(data[categorical])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized Search - Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "#from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "class PreprocessingWrapper(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_timesteps=1, n_features=7, neurons=[32, 32], activation='tanh', \n",
    "                 optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'],\n",
    "                 dropout=0.2, conv_layer=False, nfilters=64, conv_act='relu', pool_size=2, \n",
    "                 classification=True, n_predicted_timesteps = 1, epochs = 50, batch = 64, n_predicted_features = 9):\n",
    "        self.n_timesteps = n_timesteps\n",
    "        self.n_features = n_features\n",
    "        self.neurons = neurons\n",
    "        self.activation = activation\n",
    "        self.optimizer = optimizer\n",
    "        self.loss = loss\n",
    "        self.metrics = metrics\n",
    "        self.dropout = dropout\n",
    "        self.conv_layer = conv_layer\n",
    "        self.nfilters = nfilters\n",
    "        self.conv_act = conv_act\n",
    "        self.pool_size = pool_size\n",
    "        self.classification = classification\n",
    "        self.n_predicted_timesteps = n_predicted_timesteps\n",
    "        self.epochs = epochs\n",
    "        self.batch  = batch\n",
    "        self.n_predicted_features = n_predicted_features\n",
    "        \n",
    "    def create_model(self):\n",
    "\n",
    "        model = lstm(neurons=self.neurons, \n",
    "                     activation_func = self.activation, \n",
    "                     nTimesteps = self.n_timesteps, \n",
    "                     nFeatures = self.n_features, \n",
    "                     npredTimesteps = 1, \n",
    "                     npredFeatures = self.n_predicted_features, \n",
    "                     model_optimizer = self.optimizer, \n",
    "                     model_loss = self.loss, \n",
    "                     model_metrics = self.metrics, \n",
    "                     dropout=self.dropout, \n",
    "                     conv_layer=self.conv_layer, \n",
    "                     nfilters=self.nfilters, \n",
    "                     cact =self.conv_act, \n",
    "                     cpool=2,\n",
    "                     classify=self.classification)\n",
    "        return model\n",
    "    \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if self.classification:\n",
    "            self.classes_ = np.unique(y)\n",
    "        # print(f'shape of Y: {Y.shape}')\n",
    "        self.model = self.create_model()\n",
    "        self.model.fit(X, y, nEpochs = 1, nBatches= 64, val_split = 0.2, verb = 2, shuf = False)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Make predictions\n",
    "        # print(f'shape of x (predict): {X.shape}')\n",
    "        y_pred = self.model.predict(X)\n",
    "        # print(f'shape of y_pred: {y_pred.shape}')\n",
    "        y_pred = (y_pred >= 0.5).astype(float)\n",
    "        # print(y_pred[0][0])\n",
    "        return y_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_accuracy(y_true, y_pred):\n",
    "    # print(f\"Shape of y_true in custom scoring function: {y_true.shape}\")\n",
    "    # print(y_true[0][0])\n",
    "    # print(f\"Shape of y_pred in custom scoring function: {y_pred.shape}\")\n",
    "    # print(y_pred[0][0])\n",
    "\n",
    "    # # flatten\n",
    "    y_true_2d = y_true.reshape(-1, y_true.shape[2])  # Shape becomes (2148, 9)\n",
    "    y_pred_2d = y_pred.reshape(-1, y_pred.shape[2])  # Shape becomes (2148, 9)\n",
    "\n",
    "    y_true_2d = y_true_2d.astype(int)\n",
    "    y_pred_2d = y_pred_2d.astype(int)\n",
    "\n",
    "    # print(f'shape of true and pred after reshape: {y_true_2d.shape} and {y_pred_2d.shape}')\n",
    "    # print(f'type: {type(y_true_2d[0][0])}')\n",
    "    # print(f\"Data type of y_true: {y_true_2d.dtype}\")\n",
    "    # print(f\"Data type of y_pred: {y_pred_2d.dtype}\")\n",
    "\n",
    "\n",
    "    correct = np.sum(y_true == y_pred)\n",
    "    accuracy = correct / y_true.size\n",
    "\n",
    "\n",
    "    # Compute accuracy or any custom metric\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestClassifier  # Example model\n",
    "from scipy.stats import randint, uniform  # For defining distributions\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25 npast_timesteps\n",
    "- Timesteps tried are defined outside of the RandomizedSearch to make preprocessing easier and avoid nan scoring values\n",
    "- Tried to run 25, 50, 75 timesteps using for loop and list, but kernal died or randomized search terminated due to memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 11:27:57.702918: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 - 6s - 417ms/step - accuracy: 0.0419 - loss: 0.6045 - val_accuracy: 0.0000e+00 - val_loss: 0.4918\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   7.8s\n",
      "27/27 - 6s - 228ms/step - accuracy: 0.1042 - loss: 0.4985 - val_accuracy: 0.0000e+00 - val_loss: 0.3438\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   8.4s\n",
      "41/41 - 10s - 244ms/step - accuracy: 0.5739 - loss: 0.4391 - val_accuracy: 0.9442 - val_loss: 0.3595\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=  12.3s\n",
      "14/14 - 7s - 517ms/step - accuracy: 0.0000e+00 - loss: 0.6860 - val_accuracy: 0.0000e+00 - val_loss: 0.6673\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=relu, conv_layer=False, dropout=0.2, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[32, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   9.4s\n",
      "27/27 - 7s - 260ms/step - accuracy: 0.0052 - loss: 0.6249 - val_accuracy: 0.0000e+00 - val_loss: 0.4313\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=relu, conv_layer=False, dropout=0.2, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[32, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   8.7s\n",
      "41/41 - 8s - 189ms/step - accuracy: 0.1036 - loss: 0.5663 - val_accuracy: 0.0000e+00 - val_loss: 0.4489\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=relu, conv_layer=False, dropout=0.2, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[32, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   9.6s\n",
      "14/14 - 9s - 663ms/step - accuracy: 0.0105 - loss: 0.5942 - val_accuracy: 0.0047 - val_loss: 0.4179\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=  12.1s\n",
      "27/27 - 11s - 395ms/step - accuracy: 0.1135 - loss: 0.6466 - val_accuracy: 0.5581 - val_loss: 0.4531\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=  14.1s\n",
      "41/41 - 13s - 321ms/step - accuracy: 0.2499 - loss: 0.4774 - val_accuracy: 0.7163 - val_loss: 0.4651\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=  16.2s\n",
      "14/14 - 6s - 395ms/step - accuracy: 0.7299 - loss: 0.6225 - val_accuracy: 0.9628 - val_loss: 0.5325\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   7.2s\n",
      "27/27 - 6s - 234ms/step - accuracy: 0.6909 - loss: 0.5567 - val_accuracy: 0.9698 - val_loss: 0.4111\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   8.7s\n",
      "41/41 - 7s - 162ms/step - accuracy: 0.6411 - loss: 0.4998 - val_accuracy: 0.9442 - val_loss: 0.3640\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   7.5s\n",
      "14/14 - 3s - 206ms/step - accuracy: 0.0000e+00 - loss: 0.6702 - val_accuracy: 0.0000e+00 - val_loss: 0.6494\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[32, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   3.6s\n",
      "27/27 - 3s - 99ms/step - accuracy: 0.2584 - loss: 0.6036 - val_accuracy: 0.8581 - val_loss: 0.4293\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[32, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   3.3s\n",
      "41/41 - 3s - 70ms/step - accuracy: 0.6845 - loss: 0.5025 - val_accuracy: 0.9442 - val_loss: 0.4346\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[32, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   3.5s\n",
      "14/14 - 2s - 168ms/step - accuracy: 0.0559 - loss: 0.5829 - val_accuracy: 0.0047 - val_loss: 0.4415\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   3.0s\n",
      "27/27 - 3s - 101ms/step - accuracy: 0.1385 - loss: 0.5078 - val_accuracy: 0.9698 - val_loss: 0.3560\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   3.4s\n",
      "41/41 - 4s - 87ms/step - accuracy: 0.0159 - loss: 0.4411 - val_accuracy: 0.0000e+00 - val_loss: 0.3706\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   4.3s\n",
      "14/14 - 4s - 290ms/step - accuracy: 0.7416 - loss: 0.5343 - val_accuracy: 0.9628 - val_loss: 0.3867\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   5.1s\n",
      "27/27 - 4s - 146ms/step - accuracy: 0.4488 - loss: 0.4837 - val_accuracy: 0.9698 - val_loss: 0.3799\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   5.1s\n",
      "41/41 - 6s - 145ms/step - accuracy: 0.3923 - loss: 0.4340 - val_accuracy: 0.9442 - val_loss: 0.3617\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   7.1s\n",
      "14/14 - 4s - 297ms/step - accuracy: 0.1735 - loss: 0.5860 - val_accuracy: 0.9628 - val_loss: 0.6022\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=relu, conv_layer=False, dropout=0.3, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   5.2s\n",
      "27/27 - 4s - 153ms/step - accuracy: 0.2456 - loss: 0.6026 - val_accuracy: 0.9698 - val_loss: 0.4827\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=relu, conv_layer=False, dropout=0.3, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   5.2s\n",
      "41/41 - 5s - 120ms/step - accuracy: 0.2646 - loss: 0.5035 - val_accuracy: 0.0000e+00 - val_loss: 0.3891\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=relu, conv_layer=False, dropout=0.3, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   5.9s\n",
      "14/14 - 4s - 287ms/step - accuracy: 0.0512 - loss: 0.4900 - val_accuracy: 0.0047 - val_loss: 0.3777\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[128, 64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   5.1s\n",
      "27/27 - 4s - 153ms/step - accuracy: 0.6886 - loss: 0.4910 - val_accuracy: 0.9698 - val_loss: 0.3720\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[128, 64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   5.1s\n",
      "41/41 - 6s - 139ms/step - accuracy: 0.2363 - loss: 0.3988 - val_accuracy: 0.9442 - val_loss: 0.3602\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[128, 64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   6.8s\n",
      "14/14 - 2s - 171ms/step - accuracy: 0.0000e+00 - loss: 0.6654 - val_accuracy: 0.0000e+00 - val_loss: 0.6212\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.2, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   3.1s\n",
      "27/27 - 3s - 96ms/step - accuracy: 0.0017 - loss: 0.6544 - val_accuracy: 0.0000e+00 - val_loss: 0.4976\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.2, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   3.3s\n",
      "41/41 - 3s - 71ms/step - accuracy: 0.0140 - loss: 0.5975 - val_accuracy: 0.0000e+00 - val_loss: 0.5052\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.2, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   3.6s\n",
      "14/14 - 2s - 164ms/step - accuracy: 0.0827 - loss: 0.6730 - val_accuracy: 0.0000e+00 - val_loss: 0.6385\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   3.0s\n",
      "27/27 - 2s - 92ms/step - accuracy: 0.0012 - loss: 0.6727 - val_accuracy: 0.0000e+00 - val_loss: 0.6282\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   3.2s\n",
      "41/41 - 3s - 84ms/step - accuracy: 0.0287 - loss: 0.5287 - val_accuracy: 0.4465 - val_loss: 0.4421\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   4.1s\n",
      "14/14 - 3s - 242ms/step - accuracy: 0.1641 - loss: 0.6209 - val_accuracy: 0.9628 - val_loss: 0.4914\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=False, dropout=0.3, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   4.1s\n",
      "27/27 - 3s - 102ms/step - accuracy: 0.7212 - loss: 0.5300 - val_accuracy: 0.9698 - val_loss: 0.4055\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=False, dropout=0.3, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   3.5s\n",
      "41/41 - 3s - 74ms/step - accuracy: 0.3213 - loss: 0.4443 - val_accuracy: 0.9442 - val_loss: 0.3575\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=False, dropout=0.3, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   3.8s\n",
      "14/14 - 2s - 164ms/step - accuracy: 0.0605 - loss: 0.6371 - val_accuracy: 0.0000e+00 - val_loss: 0.5399\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   3.0s\n",
      "27/27 - 3s - 106ms/step - accuracy: 0.5570 - loss: 0.5055 - val_accuracy: 0.9698 - val_loss: 0.3501\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   3.8s\n",
      "41/41 - 4s - 94ms/step - accuracy: 0.3954 - loss: 0.4310 - val_accuracy: 0.9442 - val_loss: 0.3524\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   4.7s\n",
      "14/14 - 3s - 181ms/step - accuracy: 0.0081 - loss: 0.6771 - val_accuracy: 0.0000e+00 - val_loss: 0.6428\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=tanh, conv_layer=False, dropout=0.3, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   3.2s\n",
      "27/27 - 3s - 105ms/step - accuracy: 0.0384 - loss: 0.6116 - val_accuracy: 0.0605 - val_loss: 0.3985\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=tanh, conv_layer=False, dropout=0.3, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   3.6s\n",
      "41/41 - 4s - 96ms/step - accuracy: 0.0322 - loss: 0.6086 - val_accuracy: 0.2512 - val_loss: 0.5247\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=tanh, conv_layer=False, dropout=0.3, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   5.6s\n",
      "14/14 - 2s - 177ms/step - accuracy: 0.0151 - loss: 0.6064 - val_accuracy: 0.0000e+00 - val_loss: 0.5066\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.2, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   3.2s\n",
      "27/27 - 3s - 104ms/step - accuracy: 0.3533 - loss: 0.5374 - val_accuracy: 0.9698 - val_loss: 0.3765\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.2, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   3.5s\n",
      "41/41 - 3s - 77ms/step - accuracy: 0.3714 - loss: 0.4574 - val_accuracy: 0.9442 - val_loss: 0.3491\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.2, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   3.9s\n",
      "14/14 - 2s - 165ms/step - accuracy: 0.0023 - loss: 0.6727 - val_accuracy: 0.0000e+00 - val_loss: 0.6528\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   3.5s\n",
      "27/27 - 3s - 96ms/step - accuracy: 0.0460 - loss: 0.6055 - val_accuracy: 0.9372 - val_loss: 0.4172\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   3.3s\n",
      "41/41 - 3s - 73ms/step - accuracy: 0.0085 - loss: 0.5924 - val_accuracy: 0.0000e+00 - val_loss: 0.4754\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   3.7s\n",
      "14/14 - 4s - 271ms/step - accuracy: 0.0012 - loss: 0.5155 - val_accuracy: 0.0047 - val_loss: 0.3894\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[128, 64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   4.9s\n",
      "27/27 - 5s - 189ms/step - accuracy: 0.6374 - loss: 0.4528 - val_accuracy: 0.9698 - val_loss: 0.3312\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[128, 64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   6.3s\n",
      "41/41 - 5s - 131ms/step - accuracy: 0.7097 - loss: 0.3896 - val_accuracy: 0.9442 - val_loss: 0.3488\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[128, 64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   7.7s\n",
      "14/14 - 3s - 188ms/step - accuracy: 0.0000e+00 - loss: 0.6679 - val_accuracy: 0.0047 - val_loss: 0.6383\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   3.4s\n",
      "27/27 - 3s - 107ms/step - accuracy: 0.0856 - loss: 0.5672 - val_accuracy: 0.9698 - val_loss: 0.3812\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   3.6s\n",
      "41/41 - 3s - 80ms/step - accuracy: 0.0749 - loss: 0.5811 - val_accuracy: 0.9442 - val_loss: 0.4404\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   4.0s\n",
      "14/14 - 3s - 180ms/step - accuracy: 0.1327 - loss: 0.6395 - val_accuracy: 0.0000e+00 - val_loss: 0.5826\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.2, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   3.3s\n",
      "27/27 - 3s - 105ms/step - accuracy: 0.4540 - loss: 0.5916 - val_accuracy: 0.9698 - val_loss: 0.3680\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.2, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   3.6s\n",
      "41/41 - 4s - 96ms/step - accuracy: 0.1118 - loss: 0.5666 - val_accuracy: 0.1380 - val_loss: 0.4402\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.2, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   4.7s\n",
      "14/14 - 3s - 183ms/step - accuracy: 0.0035 - loss: 0.5474 - val_accuracy: 0.0047 - val_loss: 0.4292\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   3.3s\n",
      "27/27 - 3s - 110ms/step - accuracy: 0.1857 - loss: 0.5125 - val_accuracy: 0.9698 - val_loss: 0.3718\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   3.8s\n",
      "41/41 - 3s - 83ms/step - accuracy: 0.9255 - loss: 0.4173 - val_accuracy: 0.9442 - val_loss: 0.3550\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kxlee/miniconda3/envs/msse-python/lib/python3.12/site-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 - 4s - 74ms/step - accuracy: 0.5975 - loss: 0.4027 - val_accuracy: 0.9674 - val_loss: 0.2169\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "14/14 - 3s - 196ms/step - accuracy: 0.1665 - loss: 0.6301 - val_accuracy: 0.9628 - val_loss: 0.5501\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   3.5s\n",
      "27/27 - 4s - 165ms/step - accuracy: 5.8207e-04 - loss: 0.5925 - val_accuracy: 0.0000e+00 - val_loss: 0.4752\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   5.2s\n",
      "41/41 - 3s - 74ms/step - accuracy: 0.5813 - loss: 0.4839 - val_accuracy: 0.9442 - val_loss: 0.3776\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   3.8s\n",
      "14/14 - 3s - 234ms/step - accuracy: 0.0722 - loss: 0.6760 - val_accuracy: 0.0000e+00 - val_loss: 0.6365\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=relu, conv_layer=True, dropout=0.2, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[32, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   4.0s\n",
      "27/27 - 3s - 101ms/step - accuracy: 0.0099 - loss: 0.6506 - val_accuracy: 0.0000e+00 - val_loss: 0.5378\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=relu, conv_layer=True, dropout=0.2, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[32, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   3.4s\n",
      "41/41 - 3s - 68ms/step - accuracy: 0.1164 - loss: 0.5365 - val_accuracy: 0.9442 - val_loss: 0.3551\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=relu, conv_layer=True, dropout=0.2, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[32, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   3.5s\n",
      "14/14 - 3s - 242ms/step - accuracy: 0.0105 - loss: 0.6871 - val_accuracy: 0.0000e+00 - val_loss: 0.6749\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   4.3s\n",
      "27/27 - 4s - 143ms/step - accuracy: 0.0279 - loss: 0.6536 - val_accuracy: 0.0000e+00 - val_loss: 0.5171\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   4.7s\n",
      "41/41 - 4s - 95ms/step - accuracy: 0.2763 - loss: 0.5477 - val_accuracy: 0.9442 - val_loss: 0.3966\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   4.8s\n",
      "14/14 - 3s - 180ms/step - accuracy: 0.7404 - loss: 0.6483 - val_accuracy: 0.9628 - val_loss: 0.5831\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   3.2s\n",
      "27/27 - 3s - 97ms/step - accuracy: 0.2910 - loss: 0.6370 - val_accuracy: 0.9698 - val_loss: 0.5521\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   3.3s\n",
      "41/41 - 3s - 68ms/step - accuracy: 0.7939 - loss: 0.5945 - val_accuracy: 0.9442 - val_loss: 0.4557\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   3.5s\n",
      "14/14 - 3s - 225ms/step - accuracy: 0.1269 - loss: 0.6566 - val_accuracy: 0.1907 - val_loss: 0.5887\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[32, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   3.9s\n",
      "27/27 - 5s - 180ms/step - accuracy: 0.1665 - loss: 0.5711 - val_accuracy: 0.9698 - val_loss: 0.3887\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[32, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   5.6s\n",
      "41/41 - 3s - 71ms/step - accuracy: 0.7808 - loss: 0.5097 - val_accuracy: 0.9442 - val_loss: 0.3901\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[32, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   3.7s\n",
      "14/14 - 3s - 195ms/step - accuracy: 0.0105 - loss: 0.6406 - val_accuracy: 0.0047 - val_loss: 0.5666\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   3.5s\n",
      "27/27 - 3s - 105ms/step - accuracy: 0.2381 - loss: 0.5925 - val_accuracy: 0.9698 - val_loss: 0.4719\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   3.6s\n",
      "41/41 - 3s - 72ms/step - accuracy: 0.4331 - loss: 0.5351 - val_accuracy: 0.9442 - val_loss: 0.4252\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   3.7s\n",
      "14/14 - 4s - 252ms/step - accuracy: 0.0175 - loss: 0.6693 - val_accuracy: 0.0000e+00 - val_loss: 0.6234\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   4.5s\n",
      "27/27 - 4s - 138ms/step - accuracy: 0.2974 - loss: 0.6140 - val_accuracy: 0.9698 - val_loss: 0.4834\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   4.8s\n",
      "41/41 - 4s - 93ms/step - accuracy: 7.7610e-04 - loss: 0.5525 - val_accuracy: 0.0000e+00 - val_loss: 0.4210\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   5.3s\n",
      "14/14 - 3s - 247ms/step - accuracy: 0.0361 - loss: 0.6881 - val_accuracy: 0.0047 - val_loss: 0.6799\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=relu, conv_layer=True, dropout=0.3, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   4.4s\n",
      "27/27 - 5s - 168ms/step - accuracy: 0.0332 - loss: 0.6760 - val_accuracy: 0.0000e+00 - val_loss: 0.6167\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=relu, conv_layer=True, dropout=0.3, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   5.6s\n",
      "41/41 - 5s - 122ms/step - accuracy: 0.1513 - loss: 0.6071 - val_accuracy: 0.9442 - val_loss: 0.4305\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=relu, conv_layer=True, dropout=0.3, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   6.3s\n",
      "14/14 - 5s - 351ms/step - accuracy: 0.0023 - loss: 0.6750 - val_accuracy: 0.0326 - val_loss: 0.6368\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[128, 64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   8.9s\n",
      "27/27 - 6s - 223ms/step - accuracy: 0.6607 - loss: 0.6189 - val_accuracy: 0.9698 - val_loss: 0.4798\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[128, 64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   7.4s\n",
      "41/41 - 6s - 158ms/step - accuracy: 0.5669 - loss: 0.5336 - val_accuracy: 0.9442 - val_loss: 0.3761\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[128, 64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   7.9s\n",
      "14/14 - 4s - 274ms/step - accuracy: 0.3574 - loss: 0.6639 - val_accuracy: 0.0047 - val_loss: 0.5666\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.2, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   5.0s\n",
      "27/27 - 4s - 141ms/step - accuracy: 0.0279 - loss: 0.6011 - val_accuracy: 0.0000e+00 - val_loss: 0.4062\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.2, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   4.7s\n",
      "41/41 - 4s - 86ms/step - accuracy: 0.1661 - loss: 0.5238 - val_accuracy: 0.9442 - val_loss: 0.3545\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.2, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   4.4s\n",
      "14/14 - 3s - 202ms/step - accuracy: 0.0198 - loss: 0.6860 - val_accuracy: 0.0047 - val_loss: 0.6764\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   3.6s\n",
      "27/27 - 4s - 130ms/step - accuracy: 0.0029 - loss: 0.6753 - val_accuracy: 0.0000e+00 - val_loss: 0.6304\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   4.3s\n",
      "41/41 - 3s - 73ms/step - accuracy: 3.8805e-04 - loss: 0.5365 - val_accuracy: 0.0000e+00 - val_loss: 0.4518\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   3.8s\n",
      "14/14 - 3s - 190ms/step - accuracy: 0.1595 - loss: 0.6469 - val_accuracy: 0.3860 - val_loss: 0.5715\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=True, dropout=0.3, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   3.4s\n",
      "27/27 - 3s - 103ms/step - accuracy: 0.0908 - loss: 0.6034 - val_accuracy: 0.9698 - val_loss: 0.4940\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=True, dropout=0.3, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   3.5s\n",
      "41/41 - 3s - 73ms/step - accuracy: 0.4474 - loss: 0.5421 - val_accuracy: 0.9442 - val_loss: 0.3921\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=True, dropout=0.3, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   3.9s\n",
      "14/14 - 3s - 234ms/step - accuracy: 0.0012 - loss: 0.6553 - val_accuracy: 0.0000e+00 - val_loss: 0.5979\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   4.2s\n",
      "27/27 - 3s - 118ms/step - accuracy: 0.0320 - loss: 0.5784 - val_accuracy: 0.0000e+00 - val_loss: 0.4402\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   4.2s\n",
      "41/41 - 4s - 92ms/step - accuracy: 0.0175 - loss: 0.5121 - val_accuracy: 0.0000e+00 - val_loss: 0.4106\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   4.6s\n",
      "14/14 - 4s - 252ms/step - accuracy: 0.0140 - loss: 0.6492 - val_accuracy: 0.0000e+00 - val_loss: 0.5644\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=tanh, conv_layer=True, dropout=0.3, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   4.4s\n",
      "27/27 - 6s - 214ms/step - accuracy: 0.4697 - loss: 0.5468 - val_accuracy: 0.9698 - val_loss: 0.3400\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=tanh, conv_layer=True, dropout=0.3, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   6.6s\n",
      "41/41 - 3s - 81ms/step - accuracy: 0.3085 - loss: 0.5519 - val_accuracy: 0.9442 - val_loss: 0.3754\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=tanh, conv_layer=True, dropout=0.3, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   4.2s\n",
      "14/14 - 3s - 225ms/step - accuracy: 0.0244 - loss: 0.6515 - val_accuracy: 0.0000e+00 - val_loss: 0.5879\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.2, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   3.9s\n",
      "27/27 - 3s - 115ms/step - accuracy: 0.0384 - loss: 0.5907 - val_accuracy: 0.0000e+00 - val_loss: 0.4762\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.2, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   4.2s\n",
      "41/41 - 5s - 117ms/step - accuracy: 0.0667 - loss: 0.5202 - val_accuracy: 0.0000e+00 - val_loss: 0.4076\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.2, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   5.8s\n",
      "14/14 - 3s - 190ms/step - accuracy: 0.7113 - loss: 0.6850 - val_accuracy: 0.9628 - val_loss: 0.6657\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   3.4s\n",
      "27/27 - 3s - 105ms/step - accuracy: 0.2532 - loss: 0.6796 - val_accuracy: 0.9698 - val_loss: 0.6533\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   4.2s\n",
      "41/41 - 3s - 84ms/step - accuracy: 0.0000e+00 - loss: 0.5822 - val_accuracy: 0.0000e+00 - val_loss: 0.4718\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   4.5s\n",
      "14/14 - 6s - 401ms/step - accuracy: 0.6345 - loss: 0.6683 - val_accuracy: 0.9628 - val_loss: 0.6099\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[128, 64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   7.2s\n",
      "27/27 - 5s - 176ms/step - accuracy: 0.0250 - loss: 0.6122 - val_accuracy: 0.0000e+00 - val_loss: 0.4584\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[128, 64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   5.8s\n",
      "41/41 - 5s - 128ms/step - accuracy: 0.1723 - loss: 0.5547 - val_accuracy: 0.0000e+00 - val_loss: 0.3941\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[128, 64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   6.4s\n",
      "14/14 - 4s - 263ms/step - accuracy: 0.0186 - loss: 0.6834 - val_accuracy: 0.0326 - val_loss: 0.6662\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   4.6s\n",
      "27/27 - 4s - 154ms/step - accuracy: 0.0367 - loss: 0.6413 - val_accuracy: 0.0000e+00 - val_loss: 0.4788\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   5.1s\n",
      "41/41 - 3s - 80ms/step - accuracy: 0.0539 - loss: 0.5673 - val_accuracy: 0.0000e+00 - val_loss: 0.4691\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   4.0s\n",
      "14/14 - 3s - 189ms/step - accuracy: 0.0477 - loss: 0.6708 - val_accuracy: 0.0000e+00 - val_loss: 0.6174\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.2, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   3.4s\n",
      "27/27 - 3s - 106ms/step - accuracy: 0.1281 - loss: 0.5946 - val_accuracy: 0.9698 - val_loss: 0.4130\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.2, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   3.7s\n",
      "41/41 - 3s - 85ms/step - accuracy: 0.0962 - loss: 0.5719 - val_accuracy: 0.9442 - val_loss: 0.4134\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.2, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   4.4s\n",
      "14/14 - 3s - 195ms/step - accuracy: 0.8556 - loss: 0.6518 - val_accuracy: 0.9628 - val_loss: 0.5838\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   3.5s\n",
      "27/27 - 4s - 140ms/step - accuracy: 0.6793 - loss: 0.5994 - val_accuracy: 0.9698 - val_loss: 0.4743\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   4.7s\n",
      "41/41 - 9s - 218ms/step - accuracy: 0.6329 - loss: 0.5393 - val_accuracy: 0.9442 - val_loss: 0.3947\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
      "shape of y_pred: (1074, 1, 9)\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=25, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=  10.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kxlee/miniconda3/envs/msse-python/lib/python3.12/site-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 - 4s - 73ms/step - accuracy: 0.0081 - loss: 0.5471 - val_accuracy: 0.0000e+00 - val_loss: 0.3503\n"
     ]
    }
   ],
   "source": [
    "past_timepoints = [25]\n",
    "conv_layer = [False, True]\n",
    "\n",
    "best_params = []\n",
    "best_score = []\n",
    "\n",
    "for i in past_timepoints:\n",
    "    # reset x and y\n",
    "    X = np.array(data[numerical].drop(columns=['Time']))\n",
    "    Y = np.array(data[categorical])\n",
    "\n",
    "    # preprocess data\n",
    "    scalerX, X_norm = utils.scale(X)\n",
    "    scalerY, Y_norm = utils.scale(Y)\n",
    "    # print(f'x_shape scaled: {X_norm.shape}')\n",
    "    # print(f'y_shape scaled: {Y_norm.shape}')\n",
    "\n",
    "    # Reshape based on timesteps\n",
    "    [X, _] = utils.prep_lstm_data(X_norm, i, 1)\n",
    "    [_, Y] = utils.prep_lstm_data(Y_norm, i, 1)\n",
    "\n",
    "    for conv in conv_layer: \n",
    "        \"\"\"will execute with conv_layer False, then conv_layer True, \n",
    "        # must be in this order to prevent input shape error\n",
    "        # The data will reset to 2D when new npast_timesteps in the outter for loop\"\"\"\n",
    "        \n",
    "        if conv and X.ndim != 4: # reshape input\n",
    "            X = X.reshape((X.shape[0], 1, X.shape[1], X.shape[2]))\n",
    "            \n",
    "        # define parameters to gridsearch\n",
    "        param_dict = {\n",
    "        'neurons': [[32, 32], [64, 32], [128, 64, 32]],\n",
    "        'activation':[\"tanh\", 'relu'],\n",
    "        'n_timesteps':[i],\n",
    "        'n_features':[7],\n",
    "        'n_predicted_timesteps': [1],\n",
    "        'optimizer': [\"adam\"],\n",
    "        'loss': [\"binary_crossentropy\"],\n",
    "        'metrics': [[\"accuracy\"]],\n",
    "        'dropout':[0.1, 0.2, 0.3],\n",
    "        'conv_layer':[conv],\n",
    "        'nfilters':[32, 64], \n",
    "        'conv_act': ['relu', 'tanh'],\n",
    "        'pool_size':[2],\n",
    "        'classification': [True],\n",
    "        'epochs': [30, 50],\n",
    "        'batch':[32,64],\n",
    "        }\n",
    "\n",
    "\n",
    "        # print(Y.shape)\n",
    "        # print(type(Y[0][0][0]))\n",
    "\n",
    "\n",
    "        # print(Y.shape)\n",
    "        # print(type(Y[0][0][0]))\n",
    "\n",
    "        # Random Search\n",
    "        random_search = RandomizedSearchCV(\n",
    "            estimator= PreprocessingWrapper(),\n",
    "            param_distributions=param_dict,\n",
    "            n_iter = 20,  \n",
    "            scoring = make_scorer(custom_accuracy), \n",
    "            cv=tscv,  \n",
    "            verbose=2,  \n",
    "            n_jobs= 1,  \n",
    "            random_state=42  # For reproducibility\n",
    "        )\n",
    "\n",
    "        random_search.fit(X, Y)\n",
    "        best_params.append(random_search.best_params_)\n",
    "        best_score.append(random_search.best_score_)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params for 25 npast_timesteps: {'pool_size': 2, 'optimizer': 'adam', 'nfilters': 64, 'neurons': [64, 32], 'n_timesteps': 25, 'n_predicted_timesteps': 1, 'n_features': 7, 'metrics': ['accuracy'], 'loss': 'binary_crossentropy', 'epochs': 30, 'dropout': 0.1, 'conv_layer': False, 'conv_act': 'relu', 'classification': True, 'batch': 64, 'activation': 'tanh'}\n",
      "Best Score for 25 npast_timesteps: 0.8999931029726188\n"
     ]
    }
   ],
   "source": [
    "# # take the best score and find associated parameters\n",
    "\n",
    "max_index = best_score.index(max(best_score))\n",
    "print(f'Best Params for 25 npast_timesteps: {best_params[max_index]}')\n",
    "print(f'Best Score for 25 npast_timesteps: {max(best_score)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append to list\n",
    "best_scores_ = []\n",
    "best_params_ = []\n",
    "\n",
    "best_scores_.append(max(best_score))\n",
    "best_params_.append(best_params[max_index])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50 npast_timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 11:40:27.265088: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 - 3s - 201ms/step - accuracy: 0.0152 - loss: 0.5844 - val_accuracy: 0.0000e+00 - val_loss: 0.4806\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   3.8s\n",
      "27/27 - 4s - 166ms/step - accuracy: 0.0772 - loss: 0.5252 - val_accuracy: 0.9696 - val_loss: 0.4026\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   5.7s\n",
      "41/41 - 6s - 134ms/step - accuracy: 0.4499 - loss: 0.4265 - val_accuracy: 0.9438 - val_loss: 0.3607\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   6.7s\n",
      "14/14 - 4s - 289ms/step - accuracy: 0.0631 - loss: 0.6648 - val_accuracy: 0.2477 - val_loss: 0.6144\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=relu, conv_layer=False, dropout=0.2, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[32, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   5.1s\n",
      "27/27 - 4s - 144ms/step - accuracy: 0.0070 - loss: 0.6617 - val_accuracy: 0.0000e+00 - val_loss: 0.5780\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=relu, conv_layer=False, dropout=0.2, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[32, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   4.9s\n",
      "41/41 - 5s - 115ms/step - accuracy: 0.0258 - loss: 0.6467 - val_accuracy: 0.0000e+00 - val_loss: 0.5959\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=relu, conv_layer=False, dropout=0.2, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[32, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   5.7s\n",
      "14/14 - 6s - 394ms/step - accuracy: 0.0047 - loss: 0.6326 - val_accuracy: 0.0047 - val_loss: 0.4909\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   7.4s\n",
      "27/27 - 7s - 272ms/step - accuracy: 0.3915 - loss: 0.5568 - val_accuracy: 0.9696 - val_loss: 0.5293\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   9.3s\n",
      "41/41 - 10s - 248ms/step - accuracy: 0.5630 - loss: 0.5115 - val_accuracy: 0.9438 - val_loss: 0.5096\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=  12.1s\n",
      "14/14 - 3s - 229ms/step - accuracy: 0.0012 - loss: 0.6235 - val_accuracy: 0.0000e+00 - val_loss: 0.5380\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   4.3s\n",
      "27/27 - 4s - 152ms/step - accuracy: 0.0023 - loss: 0.5655 - val_accuracy: 0.0000e+00 - val_loss: 0.4439\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   5.1s\n",
      "41/41 - 5s - 119ms/step - accuracy: 0.0449 - loss: 0.5031 - val_accuracy: 0.0000e+00 - val_loss: 0.3815\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   6.0s\n",
      "14/14 - 4s - 263ms/step - accuracy: 0.8271 - loss: 0.6786 - val_accuracy: 0.9626 - val_loss: 0.6539\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[32, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   4.7s\n",
      "27/27 - 4s - 150ms/step - accuracy: 0.0129 - loss: 0.6392 - val_accuracy: 0.0000e+00 - val_loss: 0.4896\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[32, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   5.7s\n",
      "41/41 - 5s - 119ms/step - accuracy: 0.0851 - loss: 0.6145 - val_accuracy: 0.0000e+00 - val_loss: 2.5450\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[32, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   5.9s\n",
      "14/14 - 3s - 238ms/step - accuracy: 0.0023 - loss: 0.5999 - val_accuracy: 0.0047 - val_loss: 0.4598\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   4.4s\n",
      "27/27 - 4s - 160ms/step - accuracy: 0.2598 - loss: 0.5317 - val_accuracy: 0.9696 - val_loss: 0.3897\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   5.5s\n",
      "41/41 - 6s - 148ms/step - accuracy: 0.6871 - loss: 0.4304 - val_accuracy: 0.9438 - val_loss: 0.3780\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   7.2s\n",
      "14/14 - 5s - 375ms/step - accuracy: 0.5678 - loss: 0.5070 - val_accuracy: 0.9626 - val_loss: 0.4094\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   7.2s\n",
      "27/27 - 8s - 289ms/step - accuracy: 0.3657 - loss: 0.4357 - val_accuracy: 0.9696 - val_loss: 0.3266\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   9.8s\n",
      "41/41 - 9s - 226ms/step - accuracy: 0.7082 - loss: 0.4304 - val_accuracy: 0.9438 - val_loss: 0.3503\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=  11.3s\n",
      "14/14 - 6s - 428ms/step - accuracy: 0.2290 - loss: 0.6681 - val_accuracy: 0.9626 - val_loss: 0.5736\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=relu, conv_layer=False, dropout=0.3, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   8.0s\n",
      "27/27 - 8s - 289ms/step - accuracy: 0.0135 - loss: 0.5708 - val_accuracy: 0.0000e+00 - val_loss: 0.4409\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=relu, conv_layer=False, dropout=0.3, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   9.9s\n",
      "41/41 - 9s - 227ms/step - accuracy: 0.3863 - loss: 0.5171 - val_accuracy: 0.9438 - val_loss: 0.3725\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=relu, conv_layer=False, dropout=0.3, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=  11.2s\n",
      "14/14 - 5s - 380ms/step - accuracy: 0.0035 - loss: 0.5675 - val_accuracy: 0.0047 - val_loss: 0.4640\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[128, 64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   7.3s\n",
      "27/27 - 7s - 270ms/step - accuracy: 0.8455 - loss: 0.4368 - val_accuracy: 0.9696 - val_loss: 0.3420\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[128, 64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   9.4s\n",
      "41/41 - 11s - 267ms/step - accuracy: 0.4105 - loss: 0.4336 - val_accuracy: 0.9438 - val_loss: 0.3545\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[128, 64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=  13.0s\n",
      "14/14 - 3s - 245ms/step - accuracy: 0.0058 - loss: 0.6505 - val_accuracy: 0.0000e+00 - val_loss: 0.5425\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.2, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   4.5s\n",
      "27/27 - 4s - 163ms/step - accuracy: 0.0217 - loss: 0.6158 - val_accuracy: 0.0000e+00 - val_loss: 0.4648\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.2, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   5.5s\n",
      "41/41 - 6s - 135ms/step - accuracy: 0.4187 - loss: 0.5428 - val_accuracy: 0.8768 - val_loss: 0.5107\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.2, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   6.7s\n",
      "14/14 - 4s - 276ms/step - accuracy: 0.4614 - loss: 0.6699 - val_accuracy: 0.9626 - val_loss: 0.6304\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   4.9s\n",
      "27/27 - 4s - 153ms/step - accuracy: 0.6811 - loss: 0.6959 - val_accuracy: 0.9696 - val_loss: 0.5675\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   5.2s\n",
      "41/41 - 5s - 119ms/step - accuracy: 0.7140 - loss: 0.5916 - val_accuracy: 0.6849 - val_loss: 0.5426\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   5.9s\n",
      "14/14 - 5s - 322ms/step - accuracy: 0.0900 - loss: 0.6485 - val_accuracy: 0.0000e+00 - val_loss: 0.5606\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=False, dropout=0.3, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   5.9s\n",
      "27/27 - 5s - 173ms/step - accuracy: 0.5448 - loss: 0.5456 - val_accuracy: 0.9696 - val_loss: 0.4052\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=False, dropout=0.3, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   5.9s\n",
      "41/41 - 6s - 137ms/step - accuracy: 0.7917 - loss: 0.4556 - val_accuracy: 0.9438 - val_loss: 0.3614\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=False, dropout=0.3, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   6.9s\n",
      "14/14 - 5s - 359ms/step - accuracy: 0.4498 - loss: 0.5728 - val_accuracy: 0.9626 - val_loss: 0.4522\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   7.0s\n",
      "27/27 - 5s - 180ms/step - accuracy: 0.0123 - loss: 0.5584 - val_accuracy: 0.0000e+00 - val_loss: 0.4130\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   6.3s\n",
      "41/41 - 8s - 202ms/step - accuracy: 0.8369 - loss: 0.4390 - val_accuracy: 0.9438 - val_loss: 0.3604\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=  10.5s\n",
      "14/14 - 5s - 324ms/step - accuracy: 0.2091 - loss: 0.6588 - val_accuracy: 0.9626 - val_loss: 0.5689\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=tanh, conv_layer=False, dropout=0.3, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   6.3s\n",
      "27/27 - 7s - 273ms/step - accuracy: 0.4745 - loss: 0.6206 - val_accuracy: 0.9696 - val_loss: 0.4935\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=tanh, conv_layer=False, dropout=0.3, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   9.0s\n",
      "41/41 - 8s - 193ms/step - accuracy: 0.5876 - loss: 0.6007 - val_accuracy: 0.9438 - val_loss: 0.4365\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=tanh, conv_layer=False, dropout=0.3, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=  11.5s\n",
      "14/14 - 6s - 408ms/step - accuracy: 0.0105 - loss: 0.6235 - val_accuracy: 0.0000e+00 - val_loss: 0.5271\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.2, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   7.7s\n",
      "27/27 - 6s - 235ms/step - accuracy: 0.2510 - loss: 0.4776 - val_accuracy: 0.9696 - val_loss: 0.3226\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.2, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   8.0s\n",
      "41/41 - 8s - 184ms/step - accuracy: 0.5197 - loss: 0.4199 - val_accuracy: 0.9438 - val_loss: 0.3639\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.2, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   9.1s\n",
      "14/14 - 4s - 274ms/step - accuracy: 0.2255 - loss: 0.6790 - val_accuracy: 0.2897 - val_loss: 0.6552\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   5.1s\n",
      "27/27 - 5s - 181ms/step - accuracy: 0.0252 - loss: 0.6283 - val_accuracy: 0.0304 - val_loss: 0.5552\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   6.2s\n",
      "41/41 - 6s - 152ms/step - accuracy: 0.0105 - loss: 0.6075 - val_accuracy: 0.0000e+00 - val_loss: 0.5684\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   8.6s\n",
      "14/14 - 8s - 540ms/step - accuracy: 0.0689 - loss: 0.4872 - val_accuracy: 0.9626 - val_loss: 0.3607\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[128, 64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=  10.2s\n",
      "27/27 - 12s - 444ms/step - accuracy: 0.2756 - loss: 0.4205 - val_accuracy: 0.9696 - val_loss: 0.3198\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[128, 64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=  15.6s\n",
      "41/41 - 14s - 347ms/step - accuracy: 0.6902 - loss: 0.4302 - val_accuracy: 0.9438 - val_loss: 0.3455\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[128, 64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=  17.5s\n",
      "14/14 - 6s - 450ms/step - accuracy: 0.8598 - loss: 0.6652 - val_accuracy: 0.9626 - val_loss: 0.5970\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   8.3s\n",
      "27/27 - 6s - 240ms/step - accuracy: 0.0199 - loss: 0.6117 - val_accuracy: 0.0350 - val_loss: 0.4447\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   8.4s\n",
      "41/41 - 8s - 190ms/step - accuracy: 0.2758 - loss: 0.5317 - val_accuracy: 0.9438 - val_loss: 0.3738\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=  10.0s\n",
      "14/14 - 5s - 380ms/step - accuracy: 0.0245 - loss: 0.6866 - val_accuracy: 0.0000e+00 - val_loss: 0.6760\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.2, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   7.1s\n",
      "27/27 - 6s - 237ms/step - accuracy: 0.0345 - loss: 0.5948 - val_accuracy: 0.0304 - val_loss: 0.5484\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.2, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   8.5s\n",
      "41/41 - 8s - 202ms/step - accuracy: 0.4093 - loss: 0.5578 - val_accuracy: 0.9438 - val_loss: 0.4664\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.2, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=  10.3s\n",
      "14/14 - 5s - 335ms/step - accuracy: 0.0596 - loss: 0.6343 - val_accuracy: 0.9626 - val_loss: 0.5355\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   7.1s\n",
      "27/27 - 6s - 229ms/step - accuracy: 0.8561 - loss: 0.4768 - val_accuracy: 0.9696 - val_loss: 0.3523\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   8.8s\n",
      "41/41 - 8s - 199ms/step - accuracy: 0.1081 - loss: 0.4345 - val_accuracy: 0.0000e+00 - val_loss: 0.3718\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=  10.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kxlee/miniconda3/envs/msse-python/lib/python3.12/site-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 - 18s - 324ms/step - accuracy: 0.5451 - loss: 0.4980 - val_accuracy: 0.0000e+00 - val_loss: 0.4279\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "14/14 - 4s - 287ms/step - accuracy: 0.5993 - loss: 0.6167 - val_accuracy: 0.9626 - val_loss: 0.5446\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   5.2s\n",
      "27/27 - 6s - 224ms/step - accuracy: 0.1217 - loss: 0.5344 - val_accuracy: 0.0000e+00 - val_loss: 0.4179\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   7.4s\n",
      "41/41 - 5s - 120ms/step - accuracy: 0.1268 - loss: 0.5108 - val_accuracy: 0.0000e+00 - val_loss: 0.4218\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   6.1s\n",
      "14/14 - 4s - 266ms/step - accuracy: 0.0093 - loss: 0.6533 - val_accuracy: 0.0000e+00 - val_loss: 0.5600\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=relu, conv_layer=True, dropout=0.2, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[32, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   4.7s\n",
      "27/27 - 4s - 134ms/step - accuracy: 0.6167 - loss: 0.6202 - val_accuracy: 0.9696 - val_loss: 0.5137\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=relu, conv_layer=True, dropout=0.2, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[32, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   4.5s\n",
      "41/41 - 4s - 105ms/step - accuracy: 0.4042 - loss: 0.5233 - val_accuracy: 0.9438 - val_loss: 0.3687\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=relu, conv_layer=True, dropout=0.2, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[32, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   5.2s\n",
      "14/14 - 4s - 311ms/step - accuracy: 0.6519 - loss: 0.6869 - val_accuracy: 0.9626 - val_loss: 0.6676\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   5.6s\n",
      "27/27 - 5s - 180ms/step - accuracy: 0.0012 - loss: 0.6144 - val_accuracy: 0.0000e+00 - val_loss: 0.4336\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   6.1s\n",
      "41/41 - 5s - 121ms/step - accuracy: 0.1069 - loss: 0.5404 - val_accuracy: 0.9438 - val_loss: 0.3760\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   6.2s\n",
      "14/14 - 4s - 274ms/step - accuracy: 0.1659 - loss: 0.6581 - val_accuracy: 0.9626 - val_loss: 0.6115\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   4.9s\n",
      "27/27 - 4s - 138ms/step - accuracy: 0.0099 - loss: 0.6101 - val_accuracy: 0.0304 - val_loss: 0.5380\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   4.7s\n",
      "41/41 - 4s - 102ms/step - accuracy: 0.9376 - loss: 0.5670 - val_accuracy: 0.9438 - val_loss: 0.4440\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   5.1s\n",
      "14/14 - 3s - 228ms/step - accuracy: 0.0678 - loss: 0.6857 - val_accuracy: 0.0000e+00 - val_loss: 0.6670\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[32, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   4.1s\n",
      "27/27 - 4s - 140ms/step - accuracy: 0.1556 - loss: 0.5453 - val_accuracy: 0.0000e+00 - val_loss: 0.3693\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[32, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   7.0s\n",
      "41/41 - 4s - 91ms/step - accuracy: 0.0055 - loss: 0.5732 - val_accuracy: 0.0000e+00 - val_loss: 0.4447\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[32, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   4.7s\n",
      "14/14 - 4s - 257ms/step - accuracy: 0.6285 - loss: 0.6058 - val_accuracy: 0.9626 - val_loss: 0.5095\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   4.5s\n",
      "27/27 - 4s - 138ms/step - accuracy: 0.1539 - loss: 0.5466 - val_accuracy: 0.9696 - val_loss: 0.4221\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   4.7s\n",
      "41/41 - 5s - 111ms/step - accuracy: 0.3730 - loss: 0.4836 - val_accuracy: 0.9438 - val_loss: 0.3755\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   5.6s\n",
      "14/14 - 5s - 342ms/step - accuracy: 0.0210 - loss: 0.6564 - val_accuracy: 0.0000e+00 - val_loss: 0.5955\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   6.0s\n",
      "27/27 - 5s - 176ms/step - accuracy: 0.4857 - loss: 0.6025 - val_accuracy: 0.9696 - val_loss: 0.4838\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   5.9s\n",
      "41/41 - 5s - 123ms/step - accuracy: 0.7035 - loss: 0.5295 - val_accuracy: 0.9438 - val_loss: 0.3892\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   6.3s\n",
      "14/14 - 5s - 326ms/step - accuracy: 0.0269 - loss: 0.6827 - val_accuracy: 0.0000e+00 - val_loss: 0.6592\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=relu, conv_layer=True, dropout=0.3, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   5.8s\n",
      "27/27 - 5s - 178ms/step - accuracy: 0.1521 - loss: 0.6169 - val_accuracy: 0.9696 - val_loss: 0.3825\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=relu, conv_layer=True, dropout=0.3, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   6.0s\n",
      "41/41 - 7s - 182ms/step - accuracy: 0.0675 - loss: 0.5825 - val_accuracy: 0.0000e+00 - val_loss: 0.4498\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=relu, conv_layer=True, dropout=0.3, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   8.8s\n",
      "14/14 - 5s - 338ms/step - accuracy: 0.0000e+00 - loss: 0.6426 - val_accuracy: 0.0000e+00 - val_loss: 0.5743\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[128, 64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   8.6s\n",
      "27/27 - 5s - 197ms/step - accuracy: 0.0509 - loss: 0.6229 - val_accuracy: 0.9696 - val_loss: 0.5223\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[128, 64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   6.7s\n",
      "41/41 - 5s - 133ms/step - accuracy: 0.0066 - loss: 0.5535 - val_accuracy: 0.0000e+00 - val_loss: 0.4343\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[128, 64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   6.8s\n",
      "14/14 - 4s - 310ms/step - accuracy: 0.0012 - loss: 0.6451 - val_accuracy: 0.0000e+00 - val_loss: 0.5842\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.2, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   5.3s\n",
      "27/27 - 4s - 134ms/step - accuracy: 0.0088 - loss: 0.5947 - val_accuracy: 0.0000e+00 - val_loss: 0.4431\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.2, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   4.6s\n",
      "41/41 - 4s - 92ms/step - accuracy: 0.1744 - loss: 0.5108 - val_accuracy: 0.9438 - val_loss: 0.4156\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.2, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   4.8s\n",
      "14/14 - 3s - 234ms/step - accuracy: 0.0023 - loss: 0.6790 - val_accuracy: 0.0000e+00 - val_loss: 0.6575\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   4.2s\n",
      "27/27 - 3s - 129ms/step - accuracy: 0.2551 - loss: 0.5719 - val_accuracy: 0.9509 - val_loss: 0.3356\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   4.3s\n",
      "41/41 - 3s - 82ms/step - accuracy: 0.2208 - loss: 0.5170 - val_accuracy: 0.4384 - val_loss: 0.3790\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   4.2s\n",
      "14/14 - 3s - 227ms/step - accuracy: 0.0315 - loss: 0.6050 - val_accuracy: 0.0047 - val_loss: 0.5083\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=True, dropout=0.3, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   4.1s\n",
      "27/27 - 4s - 136ms/step - accuracy: 0.0468 - loss: 0.5946 - val_accuracy: 0.0000e+00 - val_loss: 0.4642\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=True, dropout=0.3, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   5.2s\n",
      "41/41 - 4s - 94ms/step - accuracy: 0.4339 - loss: 0.4915 - val_accuracy: 0.9438 - val_loss: 0.3997\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=True, dropout=0.3, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   4.8s\n",
      "14/14 - 3s - 239ms/step - accuracy: 0.0129 - loss: 0.6280 - val_accuracy: 0.0327 - val_loss: 0.5492\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   4.3s\n",
      "27/27 - 4s - 133ms/step - accuracy: 0.0012 - loss: 0.5779 - val_accuracy: 0.0000e+00 - val_loss: 0.4550\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   4.5s\n",
      "41/41 - 4s - 89ms/step - accuracy: 0.0835 - loss: 0.5125 - val_accuracy: 0.0000e+00 - val_loss: 0.3871\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   4.6s\n",
      "14/14 - 3s - 238ms/step - accuracy: 0.0140 - loss: 0.6119 - val_accuracy: 0.0000e+00 - val_loss: 0.4918\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=tanh, conv_layer=True, dropout=0.3, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   4.3s\n",
      "27/27 - 4s - 136ms/step - accuracy: 0.1960 - loss: 0.5447 - val_accuracy: 0.9696 - val_loss: 0.3637\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 107ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=tanh, conv_layer=True, dropout=0.3, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   7.7s\n",
      "41/41 - 5s - 115ms/step - accuracy: 0.2197 - loss: 0.5120 - val_accuracy: 0.9438 - val_loss: 0.3934\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=tanh, conv_layer=True, dropout=0.3, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   5.8s\n",
      "14/14 - 4s - 253ms/step - accuracy: 0.5794 - loss: 0.6252 - val_accuracy: 0.9626 - val_loss: 0.5397\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.2, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   4.5s\n",
      "27/27 - 4s - 137ms/step - accuracy: 0.1404 - loss: 0.5850 - val_accuracy: 0.0304 - val_loss: 0.4814\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.2, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   4.7s\n",
      "41/41 - 4s - 95ms/step - accuracy: 0.1803 - loss: 0.4827 - val_accuracy: 0.0000e+00 - val_loss: 0.3972\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.2, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   4.9s\n",
      "14/14 - 3s - 238ms/step - accuracy: 0.0105 - loss: 0.6770 - val_accuracy: 0.0000e+00 - val_loss: 0.6578\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   4.2s\n",
      "27/27 - 4s - 150ms/step - accuracy: 0.0076 - loss: 0.6601 - val_accuracy: 0.0000e+00 - val_loss: 0.5737\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   5.3s\n",
      "41/41 - 6s - 142ms/step - accuracy: 0.1896 - loss: 0.5761 - val_accuracy: 0.0530 - val_loss: 0.4241\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   6.9s\n",
      "14/14 - 5s - 355ms/step - accuracy: 0.0350 - loss: 0.6495 - val_accuracy: 0.0047 - val_loss: 0.5619\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[128, 64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   6.3s\n",
      "27/27 - 5s - 183ms/step - accuracy: 0.5120 - loss: 0.6171 - val_accuracy: 0.9696 - val_loss: 0.4964\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[128, 64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   6.2s\n",
      "41/41 - 5s - 130ms/step - accuracy: 0.0671 - loss: 0.5257 - val_accuracy: 0.0000e+00 - val_loss: 0.4127\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[128, 64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   6.7s\n",
      "14/14 - 3s - 238ms/step - accuracy: 0.0117 - loss: 0.6764 - val_accuracy: 0.0000e+00 - val_loss: 0.6413\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   4.3s\n",
      "27/27 - 4s - 135ms/step - accuracy: 0.0380 - loss: 0.5800 - val_accuracy: 0.9696 - val_loss: 0.4270\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   4.6s\n",
      "41/41 - 4s - 106ms/step - accuracy: 0.4128 - loss: 0.5200 - val_accuracy: 0.9438 - val_loss: 0.3891\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   5.5s\n",
      "14/14 - 3s - 234ms/step - accuracy: 0.6460 - loss: 0.5983 - val_accuracy: 0.9626 - val_loss: 0.3553\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.2, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   4.2s\n",
      "27/27 - 4s - 138ms/step - accuracy: 0.1884 - loss: 0.5329 - val_accuracy: 0.9696 - val_loss: 0.3516\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.2, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   4.8s\n",
      "41/41 - 4s - 99ms/step - accuracy: 0.0456 - loss: 0.5498 - val_accuracy: 0.0000e+00 - val_loss: 0.3988\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.2, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   5.1s\n",
      "14/14 - 4s - 264ms/step - accuracy: 0.0000e+00 - loss: 0.6144 - val_accuracy: 0.0047 - val_loss: 0.5182\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   5.0s\n",
      "27/27 - 5s - 172ms/step - accuracy: 0.1147 - loss: 0.5624 - val_accuracy: 0.9696 - val_loss: 0.4350\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   5.8s\n",
      "41/41 - 12s - 302ms/step - accuracy: 0.1198 - loss: 0.5046 - val_accuracy: 0.9438 - val_loss: 0.4132\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=50, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=  13.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kxlee/miniconda3/envs/msse-python/lib/python3.12/site-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 - 6s - 114ms/step - accuracy: 0.6915 - loss: 0.5315 - val_accuracy: 0.9673 - val_loss: 0.3426\n"
     ]
    }
   ],
   "source": [
    "past_timepoints = [50]\n",
    "conv_layer = [False, True]\n",
    "\n",
    "best_params_50 = []\n",
    "best_score_50 = []\n",
    "\n",
    "for i in past_timepoints:\n",
    "    # reset x and y\n",
    "    X = np.array(data[numerical].drop(columns=['Time']))\n",
    "    Y = np.array(data[categorical])\n",
    "\n",
    "    # preprocess data\n",
    "    scalerX, X_norm = utils.scale(X)\n",
    "    scalerY, Y_norm = utils.scale(Y)\n",
    "    # print(f'x_shape scaled: {X_norm.shape}')\n",
    "    # print(f'y_shape scaled: {Y_norm.shape}')\n",
    "\n",
    "    # Reshape based on timesteps\n",
    "    [X, _] = utils.prep_lstm_data(X_norm, i, 1)\n",
    "    [_, Y] = utils.prep_lstm_data(Y_norm, i, 1)\n",
    "\n",
    "    for conv in conv_layer: \n",
    "        \"\"\"will execute with conv_layer False, then conv_layer True, \n",
    "        # must be in this order to prevent input shape error\n",
    "        # The data will reset to 2D when new npast_timesteps in the outter for loop\"\"\"\n",
    "        \n",
    "        if conv and X.ndim != 4: # reshape input\n",
    "            X = X.reshape((X.shape[0], 1, X.shape[1], X.shape[2]))\n",
    "            \n",
    "        # define parameters to gridsearch\n",
    "        param_dict = {\n",
    "        'neurons': [[32, 32], [64, 32], [128, 64, 32]],\n",
    "        'activation':[\"tanh\", 'relu'],\n",
    "        'n_timesteps':[i],\n",
    "        'n_features':[7],\n",
    "        'n_predicted_timesteps': [1],\n",
    "        'optimizer': [\"adam\"],\n",
    "        'loss': [\"binary_crossentropy\"],\n",
    "        'metrics': [[\"accuracy\"]],\n",
    "        'dropout':[0.1, 0.2, 0.3],\n",
    "        'conv_layer':[conv],\n",
    "        'nfilters':[32, 64], \n",
    "        'conv_act': ['relu', 'tanh'],\n",
    "        'pool_size':[2],\n",
    "        'classification': [True],\n",
    "        'epochs': [30, 50],\n",
    "        'batch':[32,64],\n",
    "        }\n",
    "\n",
    "\n",
    "        # print(Y.shape)\n",
    "        # print(type(Y[0][0][0]))\n",
    "\n",
    "\n",
    "        # print(Y.shape)\n",
    "        # print(type(Y[0][0][0]))\n",
    "\n",
    "        # Random Search\n",
    "        random_search = RandomizedSearchCV(\n",
    "            estimator= PreprocessingWrapper(),\n",
    "            param_distributions=param_dict,\n",
    "            n_iter=20,  # Number of different combinations to sample\n",
    "            scoring = make_scorer(custom_accuracy), \n",
    "            cv=tscv,  # Number of cross-validation folds\n",
    "            verbose=2,  # Display search progress\n",
    "            n_jobs= 1,  # Use all available CPUs\n",
    "            random_state=42  # For reproducibility\n",
    "        )\n",
    "\n",
    "        random_search.fit(X, Y)\n",
    "        best_params_50.append(random_search.best_params_)\n",
    "        best_score_50.append(random_search.best_score_)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params for 50 npast_timesteps: {'pool_size': 2, 'optimizer': 'adam', 'nfilters': 32, 'neurons': [128, 64, 32], 'n_timesteps': 50, 'n_predicted_timesteps': 1, 'n_features': 7, 'metrics': ['accuracy'], 'loss': 'binary_crossentropy', 'epochs': 30, 'dropout': 0.1, 'conv_layer': False, 'conv_act': 'tanh', 'classification': True, 'batch': 64, 'activation': 'relu'}\n",
      "Best Scorefor 50 npast_timesteps: 0.8993370127390746\n"
     ]
    }
   ],
   "source": [
    "# take the best score and find associated parameters\n",
    "\n",
    "max_index_50 = best_score_50.index(max(best_score_50))\n",
    "print(f'Best Params for 50 npast_timesteps: {best_params_50[max_index_50]}')\n",
    "print(f'Best Scorefor 50 npast_timesteps: {max(best_score_50)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_scores_.append(max(best_score_50))\n",
    "best_params_.append(best_params_50[max_index_50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 75 npast_timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 11:55:28.332335: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 - 6s - 423ms/step - accuracy: 0.6694 - loss: 0.5869 - val_accuracy: 0.9624 - val_loss: 0.4511\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   8.2s\n",
      "27/27 - 7s - 269ms/step - accuracy: 0.6492 - loss: 0.5025 - val_accuracy: 0.9694 - val_loss: 0.3635\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   9.1s\n",
      "40/40 - 9s - 230ms/step - accuracy: 0.6064 - loss: 0.4332 - val_accuracy: 0.9498 - val_loss: 0.3569\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=  10.7s\n",
      "14/14 - 5s - 340ms/step - accuracy: 0.4612 - loss: 0.6461 - val_accuracy: 0.9624 - val_loss: 0.5818\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=relu, conv_layer=False, dropout=0.2, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[32, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   6.8s\n",
      "27/27 - 8s - 314ms/step - accuracy: 0.0059 - loss: 0.7065 - val_accuracy: 0.0000e+00 - val_loss: 1.4971\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=relu, conv_layer=False, dropout=0.2, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[32, 32], nfilters=64, optimizer=adam, pool_size=2; total time=  10.8s\n",
      "40/40 - 8s - 205ms/step - accuracy: 0.0381 - loss: 0.5424 - val_accuracy: 0.0000e+00 - val_loss: 0.4981\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=relu, conv_layer=False, dropout=0.2, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[32, 32], nfilters=64, optimizer=adam, pool_size=2; total time=  10.3s\n",
      "14/14 - 9s - 613ms/step - accuracy: 0.0035 - loss: 0.6641 - val_accuracy: 0.0000e+00 - val_loss: 0.7101\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=  11.3s\n",
      "27/27 - 12s - 460ms/step - accuracy: 0.0082 - loss: 0.6846 - val_accuracy: 0.0000e+00 - val_loss: 0.5589\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=  15.7s\n",
      "40/40 - 16s - 389ms/step - accuracy: 0.0510 - loss: 0.6416 - val_accuracy: 0.5479 - val_loss: 0.8919\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=  19.1s\n",
      "14/14 - 5s - 372ms/step - accuracy: 0.3118 - loss: 0.6349 - val_accuracy: 0.9624 - val_loss: 0.5475\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   6.9s\n",
      "27/27 - 6s - 232ms/step - accuracy: 0.0018 - loss: 0.5271 - val_accuracy: 0.0000e+00 - val_loss: 0.3817\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   8.1s\n",
      "40/40 - 8s - 201ms/step - accuracy: 0.0389 - loss: 0.4808 - val_accuracy: 0.0000e+00 - val_loss: 0.3840\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   9.9s\n",
      "14/14 - 5s - 365ms/step - accuracy: 0.1706 - loss: 0.6792 - val_accuracy: 0.0329 - val_loss: 0.6623\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[32, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   6.8s\n",
      "27/27 - 7s - 244ms/step - accuracy: 0.3384 - loss: 0.6597 - val_accuracy: 0.8706 - val_loss: 0.7717\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[32, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   8.1s\n",
      "40/40 - 7s - 185ms/step - accuracy: 0.6197 - loss: 0.5960 - val_accuracy: 0.9498 - val_loss: 0.4985\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[32, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   8.8s\n",
      "14/14 - 4s - 320ms/step - accuracy: 0.4082 - loss: 0.5827 - val_accuracy: 0.9624 - val_loss: 0.4836\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   6.2s\n",
      "27/27 - 6s - 204ms/step - accuracy: 0.2084 - loss: 0.5019 - val_accuracy: 0.9694 - val_loss: 0.3818\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   7.0s\n",
      "40/40 - 8s - 208ms/step - accuracy: 0.3002 - loss: 0.4413 - val_accuracy: 0.9498 - val_loss: 0.3598\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   9.8s\n",
      "14/14 - 7s - 466ms/step - accuracy: 0.0000e+00 - loss: 0.5188 - val_accuracy: 0.0047 - val_loss: 0.3978\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   9.3s\n",
      "27/27 - 10s - 353ms/step - accuracy: 0.1177 - loss: 0.4558 - val_accuracy: 0.9694 - val_loss: 0.3651\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=  12.3s\n",
      "40/40 - 13s - 329ms/step - accuracy: 0.1154 - loss: 0.4204 - val_accuracy: 0.0000e+00 - val_loss: 0.3682\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=  15.8s\n",
      "14/14 - 7s - 510ms/step - accuracy: 0.0600 - loss: 0.6592 - val_accuracy: 0.9624 - val_loss: 0.5760\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=relu, conv_layer=False, dropout=0.3, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   9.8s\n",
      "27/27 - 9s - 350ms/step - accuracy: 0.3284 - loss: 0.5877 - val_accuracy: 0.9694 - val_loss: 0.4595\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=relu, conv_layer=False, dropout=0.3, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=  12.0s\n",
      "40/40 - 13s - 328ms/step - accuracy: 0.6715 - loss: 0.5079 - val_accuracy: 0.9482 - val_loss: 0.7566\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=relu, conv_layer=False, dropout=0.3, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=  15.6s\n",
      "14/14 - 6s - 463ms/step - accuracy: 0.1588 - loss: 0.5100 - val_accuracy: 0.0047 - val_loss: 0.3973\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[128, 64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   9.3s\n",
      "27/27 - 10s - 353ms/step - accuracy: 0.0194 - loss: 0.4687 - val_accuracy: 0.0000e+00 - val_loss: 0.3745\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[128, 64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=  12.8s\n",
      "40/40 - 17s - 430ms/step - accuracy: 0.2331 - loss: 0.4234 - val_accuracy: 0.9498 - val_loss: 0.3649\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[128, 64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=  26.4s\n",
      "14/14 - 5s - 359ms/step - accuracy: 0.2247 - loss: 0.6265 - val_accuracy: 0.0047 - val_loss: 0.3700\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.2, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   6.8s\n",
      "27/27 - 7s - 248ms/step - accuracy: 0.3761 - loss: 0.6106 - val_accuracy: 0.9694 - val_loss: 0.5738\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.2, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   8.2s\n",
      "40/40 - 8s - 203ms/step - accuracy: 0.0043 - loss: 0.6447 - val_accuracy: 0.0000e+00 - val_loss: 0.6007\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.2, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   9.7s\n",
      "14/14 - 4s - 306ms/step - accuracy: 0.1494 - loss: 0.6189 - val_accuracy: 0.0000e+00 - val_loss: 0.5058\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   5.8s\n",
      "27/27 - 6s - 240ms/step - accuracy: 0.1377 - loss: 1.1113 - val_accuracy: 0.6400 - val_loss: 3.0970\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   8.4s\n",
      "40/40 - 7s - 175ms/step - accuracy: 0.4003 - loss: 0.5833 - val_accuracy: 0.8885 - val_loss: 0.5009\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   8.4s\n",
      "14/14 - 5s - 365ms/step - accuracy: 0.1788 - loss: 0.5653 - val_accuracy: 0.9624 - val_loss: 0.4342\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=False, dropout=0.3, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   6.5s\n",
      "27/27 - 6s - 214ms/step - accuracy: 0.0283 - loss: 0.5164 - val_accuracy: 0.0000e+00 - val_loss: 0.3843\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=False, dropout=0.3, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   7.3s\n",
      "40/40 - 7s - 181ms/step - accuracy: 0.5911 - loss: 0.4532 - val_accuracy: 0.9498 - val_loss: 0.3559\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=False, dropout=0.3, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   9.3s\n",
      "14/14 - 4s - 285ms/step - accuracy: 0.0212 - loss: 0.5918 - val_accuracy: 0.0047 - val_loss: 0.4684\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   5.5s\n",
      "27/27 - 6s - 217ms/step - accuracy: 0.0135 - loss: 0.5175 - val_accuracy: 0.0000e+00 - val_loss: 0.3677\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   8.3s\n",
      "40/40 - 7s - 180ms/step - accuracy: 0.8783 - loss: 0.4216 - val_accuracy: 0.9498 - val_loss: 0.3452\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=tanh, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   8.6s\n",
      "14/14 - 4s - 287ms/step - accuracy: 0.1376 - loss: 0.6659 - val_accuracy: 0.0329 - val_loss: 0.6118\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=tanh, conv_layer=False, dropout=0.3, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   5.4s\n",
      "27/27 - 6s - 230ms/step - accuracy: 0.5533 - loss: 0.5720 - val_accuracy: 0.9694 - val_loss: 0.5197\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=tanh, conv_layer=False, dropout=0.3, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   7.6s\n",
      "40/40 - 7s - 176ms/step - accuracy: 0.0012 - loss: 0.5725 - val_accuracy: 0.0000e+00 - val_loss: 0.4854\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=tanh, conv_layer=False, dropout=0.3, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   9.7s\n",
      "14/14 - 4s - 294ms/step - accuracy: 0.0000e+00 - loss: 0.5896 - val_accuracy: 0.0047 - val_loss: 0.4815\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.2, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   5.6s\n",
      "27/27 - 7s - 247ms/step - accuracy: 0.1360 - loss: 0.5319 - val_accuracy: 0.9694 - val_loss: 0.4118\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.2, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   8.3s\n",
      "40/40 - 8s - 195ms/step - accuracy: 0.5051 - loss: 0.4704 - val_accuracy: 0.9498 - val_loss: 0.3634\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=False, dropout=0.2, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   9.2s\n",
      "14/14 - 4s - 266ms/step - accuracy: 0.0082 - loss: 0.6779 - val_accuracy: 0.0000e+00 - val_loss: 0.6613\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   5.0s\n",
      "27/27 - 5s - 187ms/step - accuracy: 0.0141 - loss: 0.6274 - val_accuracy: 0.0000e+00 - val_loss: 0.5495\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   6.4s\n",
      "40/40 - 6s - 162ms/step - accuracy: 0.0110 - loss: 0.6366 - val_accuracy: 0.1915 - val_loss: 0.5847\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   7.8s\n",
      "14/14 - 6s - 459ms/step - accuracy: 0.1247 - loss: 0.4987 - val_accuracy: 0.0047 - val_loss: 0.3662\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[128, 64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   9.2s\n",
      "27/27 - 10s - 372ms/step - accuracy: 0.0459 - loss: 0.4810 - val_accuracy: 0.0000e+00 - val_loss: 0.3688\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[128, 64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=  12.9s\n",
      "40/40 - 13s - 313ms/step - accuracy: 0.6193 - loss: 0.3784 - val_accuracy: 0.9498 - val_loss: 0.3697\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 109ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[128, 64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=  16.7s\n",
      "14/14 - 5s - 335ms/step - accuracy: 0.0518 - loss: 0.6630 - val_accuracy: 0.0047 - val_loss: 0.5842\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   6.2s\n",
      "27/27 - 6s - 214ms/step - accuracy: 0.9417 - loss: 0.5787 - val_accuracy: 0.9694 - val_loss: 0.4560\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   7.2s\n",
      "40/40 - 7s - 182ms/step - accuracy: 0.2284 - loss: 0.6187 - val_accuracy: 0.6672 - val_loss: 0.4601\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   8.8s\n",
      "14/14 - 4s - 288ms/step - accuracy: 0.0635 - loss: 0.6540 - val_accuracy: 0.0141 - val_loss: 0.5769\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.2, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   5.4s\n",
      "27/27 - 6s - 209ms/step - accuracy: 0.1189 - loss: 0.6438 - val_accuracy: 0.0353 - val_loss: 0.5718\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.2, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   7.1s\n",
      "40/40 - 8s - 201ms/step - accuracy: 0.0420 - loss: 0.6787 - val_accuracy: 0.6876 - val_loss: 0.5842\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.2, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   9.6s\n",
      "14/14 - 4s - 281ms/step - accuracy: 0.6541 - loss: 0.5706 - val_accuracy: 0.9624 - val_loss: 0.4394\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   5.3s\n",
      "27/27 - 6s - 228ms/step - accuracy: 5.8858e-04 - loss: 0.5251 - val_accuracy: 0.0000e+00 - val_loss: 0.3867\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   8.0s\n",
      "40/40 - 8s - 195ms/step - accuracy: 0.5589 - loss: 0.4320 - val_accuracy: 0.9498 - val_loss: 0.3581\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=relu, conv_layer=False, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   9.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kxlee/miniconda3/envs/msse-python/lib/python3.12/site-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 - 17s - 317ms/step - accuracy: 0.2356 - loss: 0.6013 - val_accuracy: 0.9671 - val_loss: 0.5133\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "14/14 - 3s - 224ms/step - accuracy: 0.7753 - loss: 0.6218 - val_accuracy: 0.9624 - val_loss: 0.5435\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   4.0s\n",
      "27/27 - 5s - 185ms/step - accuracy: 0.5921 - loss: 0.4843 - val_accuracy: 0.9694 - val_loss: 0.3808\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   5.9s\n",
      "40/40 - 4s - 100ms/step - accuracy: 0.0620 - loss: 0.5247 - val_accuracy: 0.0000e+00 - val_loss: 0.4459\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   5.0s\n",
      "14/14 - 3s - 224ms/step - accuracy: 0.2753 - loss: 0.6689 - val_accuracy: 0.9624 - val_loss: 0.6050\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=relu, conv_layer=True, dropout=0.2, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[32, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   4.5s\n",
      "27/27 - 3s - 122ms/step - accuracy: 0.4974 - loss: 0.6097 - val_accuracy: 0.9694 - val_loss: 0.5016\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=relu, conv_layer=True, dropout=0.2, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[32, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   4.2s\n",
      "40/40 - 3s - 80ms/step - accuracy: 0.1845 - loss: 0.5190 - val_accuracy: 0.9498 - val_loss: 0.3663\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=relu, conv_layer=True, dropout=0.2, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[32, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   4.1s\n",
      "14/14 - 4s - 286ms/step - accuracy: 0.0329 - loss: 0.6715 - val_accuracy: 0.0000e+00 - val_loss: 0.5742\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   5.2s\n",
      "27/27 - 4s - 153ms/step - accuracy: 0.8005 - loss: 0.5748 - val_accuracy: 0.9694 - val_loss: 0.6346\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   5.3s\n",
      "40/40 - 5s - 113ms/step - accuracy: 0.3666 - loss: 0.4834 - val_accuracy: 0.9498 - val_loss: 0.3806\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   5.6s\n",
      "14/14 - 3s - 201ms/step - accuracy: 0.7118 - loss: 0.6209 - val_accuracy: 0.9624 - val_loss: 0.5542\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   3.6s\n",
      "27/27 - 3s - 108ms/step - accuracy: 0.0188 - loss: 0.6058 - val_accuracy: 0.0000e+00 - val_loss: 0.5282\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   3.8s\n",
      "40/40 - 3s - 77ms/step - accuracy: 0.7936 - loss: 0.5501 - val_accuracy: 0.9498 - val_loss: 0.4504\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   4.5s\n",
      "14/14 - 5s - 350ms/step - accuracy: 0.2671 - loss: 0.6162 - val_accuracy: 0.9624 - val_loss: 0.4953\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[32, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   5.8s\n",
      "27/27 - 3s - 119ms/step - accuracy: 0.3773 - loss: 0.5571 - val_accuracy: 0.9694 - val_loss: 0.4194\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[32, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   4.1s\n",
      "40/40 - 4s - 90ms/step - accuracy: 0.1197 - loss: 0.4882 - val_accuracy: 0.0000e+00 - val_loss: 0.4065\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[32, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   5.1s\n",
      "14/14 - 3s - 208ms/step - accuracy: 0.0176 - loss: 0.6136 - val_accuracy: 0.0000e+00 - val_loss: 0.5275\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   3.7s\n",
      "27/27 - 3s - 119ms/step - accuracy: 0.6992 - loss: 0.5480 - val_accuracy: 0.9694 - val_loss: 0.4360\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   4.1s\n",
      "40/40 - 3s - 87ms/step - accuracy: 0.6036 - loss: 0.5036 - val_accuracy: 0.9498 - val_loss: 0.3918\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   4.4s\n",
      "14/14 - 4s - 313ms/step - accuracy: 0.2741 - loss: 0.6438 - val_accuracy: 0.9624 - val_loss: 0.5687\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   5.5s\n",
      "27/27 - 4s - 149ms/step - accuracy: 0.3408 - loss: 0.5729 - val_accuracy: 0.0000e+00 - val_loss: 0.4260\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   5.1s\n",
      "40/40 - 5s - 114ms/step - accuracy: 0.9195 - loss: 0.5049 - val_accuracy: 0.9498 - val_loss: 0.3689\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   5.7s\n",
      "14/14 - 4s - 284ms/step - accuracy: 0.1882 - loss: 0.6862 - val_accuracy: 0.9624 - val_loss: 0.6609\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=relu, conv_layer=True, dropout=0.3, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   5.1s\n",
      "27/27 - 5s - 169ms/step - accuracy: 0.0371 - loss: 0.6358 - val_accuracy: 0.9694 - val_loss: 0.4040\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=relu, conv_layer=True, dropout=0.3, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   5.8s\n",
      "40/40 - 5s - 116ms/step - accuracy: 0.0549 - loss: 0.5443 - val_accuracy: 0.0000e+00 - val_loss: 0.3915\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=relu, conv_layer=True, dropout=0.3, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[128, 64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   5.7s\n",
      "14/14 - 8s - 553ms/step - accuracy: 0.7647 - loss: 0.6387 - val_accuracy: 0.9624 - val_loss: 0.5501\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[128, 64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   8.9s\n",
      "27/27 - 5s - 171ms/step - accuracy: 0.3673 - loss: 0.5888 - val_accuracy: 0.9694 - val_loss: 0.4424\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[128, 64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   5.8s\n",
      "40/40 - 6s - 138ms/step - accuracy: 0.4478 - loss: 0.4975 - val_accuracy: 0.9498 - val_loss: 0.3775\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[128, 64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   6.7s\n",
      "14/14 - 3s - 198ms/step - accuracy: 0.4553 - loss: 0.6564 - val_accuracy: 0.9624 - val_loss: 0.5386\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.2, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   3.6s\n",
      "27/27 - 3s - 116ms/step - accuracy: 0.1948 - loss: 0.5524 - val_accuracy: 0.9694 - val_loss: 0.3930\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.2, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   4.1s\n",
      "40/40 - 4s - 93ms/step - accuracy: 0.5789 - loss: 0.5104 - val_accuracy: 0.0000e+00 - val_loss: 0.4000\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
      "[CV] END activation=relu, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.2, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   4.7s\n",
      "14/14 - 4s - 279ms/step - accuracy: 0.0082 - loss: 0.6821 - val_accuracy: 0.0047 - val_loss: 0.6553\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   5.0s\n",
      "27/27 - 4s - 152ms/step - accuracy: 0.0594 - loss: 0.5865 - val_accuracy: 0.0000e+00 - val_loss: 0.3517\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   5.2s\n",
      "40/40 - 4s - 106ms/step - accuracy: 0.0145 - loss: 0.5614 - val_accuracy: 0.0000e+00 - val_loss: 0.4630\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   5.4s\n",
      "14/14 - 4s - 284ms/step - accuracy: 0.0565 - loss: 0.6170 - val_accuracy: 0.0000e+00 - val_loss: 0.5439\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=True, dropout=0.3, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   5.1s\n",
      "27/27 - 4s - 160ms/step - accuracy: 0.1660 - loss: 0.5655 - val_accuracy: 0.9694 - val_loss: 0.4571\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=True, dropout=0.3, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   5.5s\n",
      "40/40 - 4s - 111ms/step - accuracy: 0.5628 - loss: 0.4832 - val_accuracy: 0.9498 - val_loss: 0.3740\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=True, dropout=0.3, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   5.5s\n",
      "14/14 - 4s - 295ms/step - accuracy: 0.9071 - loss: 0.5916 - val_accuracy: 0.9624 - val_loss: 0.4794\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   5.0s\n",
      "27/27 - 4s - 130ms/step - accuracy: 0.2531 - loss: 0.5333 - val_accuracy: 0.9694 - val_loss: 0.4215\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   4.4s\n",
      "40/40 - 3s - 86ms/step - accuracy: 0.5506 - loss: 0.4815 - val_accuracy: 0.9498 - val_loss: 0.3970\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=tanh, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   4.3s\n",
      "14/14 - 3s - 238ms/step - accuracy: 0.0047 - loss: 0.6302 - val_accuracy: 0.0047 - val_loss: 0.4595\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=tanh, conv_layer=True, dropout=0.3, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   4.2s\n",
      "27/27 - 8s - 292ms/step - accuracy: 0.4491 - loss: 0.5403 - val_accuracy: 0.9694 - val_loss: 0.4000\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=tanh, conv_layer=True, dropout=0.3, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   9.1s\n",
      "40/40 - 4s - 110ms/step - accuracy: 0.2688 - loss: 0.5592 - val_accuracy: 0.9498 - val_loss: 0.3768\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=tanh, conv_layer=True, dropout=0.3, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   5.5s\n",
      "14/14 - 4s - 289ms/step - accuracy: 0.0435 - loss: 0.6178 - val_accuracy: 0.0047 - val_loss: 0.5328\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.2, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   4.9s\n",
      "27/27 - 4s - 138ms/step - accuracy: 0.0035 - loss: 0.5724 - val_accuracy: 0.0000e+00 - val_loss: 0.4758\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.2, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   4.7s\n",
      "40/40 - 3s - 83ms/step - accuracy: 0.0510 - loss: 0.5128 - val_accuracy: 0.0000e+00 - val_loss: 0.4291\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=tanh, conv_layer=True, dropout=0.2, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   4.2s\n",
      "14/14 - 3s - 203ms/step - accuracy: 0.2506 - loss: 0.6746 - val_accuracy: 0.0000e+00 - val_loss: 0.6222\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   3.6s\n",
      "27/27 - 3s - 111ms/step - accuracy: 0.3726 - loss: 0.5351 - val_accuracy: 0.9694 - val_loss: 0.3970\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   3.9s\n",
      "40/40 - 4s - 94ms/step - accuracy: 0.2665 - loss: 0.5002 - val_accuracy: 0.7677 - val_loss: 0.4138\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[32, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   4.6s\n",
      "14/14 - 5s - 380ms/step - accuracy: 0.1259 - loss: 0.6646 - val_accuracy: 0.9624 - val_loss: 0.6131\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[128, 64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   6.7s\n",
      "27/27 - 5s - 186ms/step - accuracy: 0.3743 - loss: 0.5952 - val_accuracy: 0.9694 - val_loss: 0.4458\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[128, 64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   6.2s\n",
      "40/40 - 6s - 149ms/step - accuracy: 0.8026 - loss: 0.5461 - val_accuracy: 0.9498 - val_loss: 0.4129\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step\n",
      "[CV] END activation=tanh, batch=32, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[128, 64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   7.3s\n",
      "14/14 - 4s - 304ms/step - accuracy: 0.1000 - loss: 0.6542 - val_accuracy: 0.0329 - val_loss: 0.5443\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   5.2s\n",
      "27/27 - 3s - 127ms/step - accuracy: 0.0012 - loss: 0.5759 - val_accuracy: 0.0000e+00 - val_loss: 0.3859\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   4.3s\n",
      "40/40 - 3s - 85ms/step - accuracy: 0.5173 - loss: 0.4625 - val_accuracy: 0.0078 - val_loss: 0.4027\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=32, optimizer=adam, pool_size=2; total time=   4.3s\n",
      "14/14 - 4s - 278ms/step - accuracy: 0.0588 - loss: 0.6418 - val_accuracy: 0.0047 - val_loss: 0.4648\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.2, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   4.8s\n",
      "27/27 - 5s - 174ms/step - accuracy: 0.1012 - loss: 0.5887 - val_accuracy: 0.9694 - val_loss: 0.4939\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.2, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   5.5s\n",
      "40/40 - 4s - 103ms/step - accuracy: 0.1071 - loss: 0.5004 - val_accuracy: 0.9498 - val_loss: 0.4059\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
      "[CV] END activation=relu, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.2, epochs=50, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   5.2s\n",
      "14/14 - 4s - 275ms/step - accuracy: 0.0165 - loss: 0.6012 - val_accuracy: 0.0000e+00 - val_loss: 0.5259\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   5.1s\n",
      "27/27 - 4s - 143ms/step - accuracy: 0.4915 - loss: 0.5194 - val_accuracy: 0.9694 - val_loss: 0.4185\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   4.7s\n",
      "40/40 - 8s - 197ms/step - accuracy: 0.7645 - loss: 0.5046 - val_accuracy: 0.9498 - val_loss: 0.4135\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n",
      "[CV] END activation=tanh, batch=64, classification=True, conv_act=relu, conv_layer=True, dropout=0.1, epochs=30, loss=binary_crossentropy, metrics=['accuracy'], n_features=7, n_predicted_timesteps=1, n_timesteps=75, neurons=[64, 32], nfilters=64, optimizer=adam, pool_size=2; total time=   9.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kxlee/miniconda3/envs/msse-python/lib/python3.12/site-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 - 5s - 97ms/step - accuracy: 0.1428 - loss: 0.4902 - val_accuracy: 0.9671 - val_loss: 0.2961\n"
     ]
    }
   ],
   "source": [
    "past_timepoints = [75]\n",
    "conv_layer = [False, True]\n",
    "\n",
    "best_params_75 = []\n",
    "best_score_75 = []\n",
    "\n",
    "for i in past_timepoints:\n",
    "    # reset x and y\n",
    "    X = np.array(data[numerical].drop(columns=['Time']))\n",
    "    Y = np.array(data[categorical])\n",
    "\n",
    "    # preprocess data\n",
    "    scalerX, X_norm = utils.scale(X)\n",
    "    scalerY, Y_norm = utils.scale(Y)\n",
    "    # print(f'x_shape scaled: {X_norm.shape}')\n",
    "    # print(f'y_shape scaled: {Y_norm.shape}')\n",
    "\n",
    "    # Reshape based on timesteps\n",
    "    [X, _] = utils.prep_lstm_data(X_norm, i, 1)\n",
    "    [_, Y] = utils.prep_lstm_data(Y_norm, i, 1)\n",
    "\n",
    "    for conv in conv_layer: \n",
    "        \"\"\"will execute with conv_layer False, then conv_layer True, \n",
    "        # must be in this order to prevent input shape error\n",
    "        # The data will reset to 2D when new npast_timesteps in the outter for loop\"\"\"\n",
    "        \n",
    "        if conv and X.ndim != 4: # reshape input\n",
    "            X = X.reshape((X.shape[0], 1, X.shape[1], X.shape[2]))\n",
    "            \n",
    "        # define parameters to gridsearch\n",
    "        param_dict = {\n",
    "        'neurons': [[32, 32], [64, 32], [128, 64, 32]],\n",
    "        'activation':[\"tanh\", 'relu'],\n",
    "        'n_timesteps':[i],\n",
    "        'n_features':[7],\n",
    "        'n_predicted_timesteps': [1],\n",
    "        'optimizer': [\"adam\"],\n",
    "        'loss': [\"binary_crossentropy\"],\n",
    "        'metrics': [[\"accuracy\"]],\n",
    "        'dropout':[0.1, 0.2, 0.3],\n",
    "        'conv_layer':[conv],\n",
    "        'nfilters':[32, 64], \n",
    "        'conv_act': ['relu', 'tanh'],\n",
    "        'pool_size':[2],\n",
    "        'classification': [True],\n",
    "        'epochs': [30, 50],\n",
    "        'batch':[32,64],\n",
    "        }\n",
    "\n",
    "\n",
    "        # print(Y.shape)\n",
    "        # print(type(Y[0][0][0]))\n",
    "\n",
    "\n",
    "        # print(Y.shape)\n",
    "        # print(type(Y[0][0][0]))\n",
    "\n",
    "        # Random Search\n",
    "        random_search = RandomizedSearchCV(\n",
    "            estimator= PreprocessingWrapper(),\n",
    "            param_distributions=param_dict,\n",
    "            n_iter=20,  # Number of different combinations to sample\n",
    "            scoring = make_scorer(custom_accuracy), \n",
    "            cv=tscv,  # Number of cross-validation folds\n",
    "            verbose=2,  # Display search progress\n",
    "            n_jobs= 1,  # Use all available CPUs\n",
    "            random_state=42  # For reproducibility\n",
    "        )\n",
    "\n",
    "        random_search.fit(X, Y)\n",
    "        best_params_75.append(random_search.best_params_)\n",
    "        best_score_75.append(random_search.best_score_)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params for 75 npast_timesteps: {'pool_size': 2, 'optimizer': 'adam', 'nfilters': 32, 'neurons': [128, 64, 32], 'n_timesteps': 75, 'n_predicted_timesteps': 1, 'n_features': 7, 'metrics': ['accuracy'], 'loss': 'binary_crossentropy', 'epochs': 30, 'dropout': 0.3, 'conv_layer': False, 'conv_act': 'relu', 'classification': True, 'batch': 32, 'activation': 'relu'}\n",
      "Best Scorefor 75 npast_timesteps: 0.9011414807833281\n"
     ]
    }
   ],
   "source": [
    "# take the best score and find associated parameters\n",
    "\n",
    "max_index_75 = best_score_75.index(max(best_score_75))\n",
    "print(f'Best Params for 75 npast_timesteps: {best_params_75[max_index_75]}')\n",
    "print(f'Best Scorefor 75 npast_timesteps: {max(best_score_75)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_scores_.append(max(best_score_75))\n",
    "best_params_.append(best_params_75[max_index_75])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Parameters for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_index_all = best_scores_.index(max(best_scores_))\n",
    "best_params_all = best_params_[max_index_all]\n",
    "\n",
    "print(f'Best Params for Classification: {best_params_all}')\n",
    "print(f'Best Score for Classification: {max(best_scores_)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add manually to list becuase kernal crashed, this was test run with 10 iterations, cv = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9011414807833281\n",
      "2\n",
      "{'pool_size': 2, 'optimizer': 'adam', 'nfilters': 32, 'neurons': [128, 64, 32], 'n_timesteps': 75, 'n_predicted_timesteps': 1, 'n_features': 7, 'metrics': ['accuracy'], 'loss': 'binary_crossentropy', 'epochs': 30, 'dropout': 0.3, 'conv_layer': False, 'conv_act': 'relu', 'classification': True, 'batch': 32, 'activation': 'relu'}\n"
     ]
    }
   ],
   "source": [
    "scores = [0.8999931029726188, 0.8993370127390746,  0.9011414807833281]\n",
    "params = [{'pool_size': 2, 'optimizer': 'adam', 'nfilters': 64, 'neurons': [64, 32], 'n_timesteps': 25, 'n_predicted_timesteps': 1, 'n_features': 7, 'metrics': ['accuracy'], 'loss': 'binary_crossentropy', 'epochs': 30, 'dropout': 0.1, 'conv_layer': False, 'conv_act': 'relu', 'classification': True, 'batch': 64, 'activation': 'tanh'},\n",
    "          {'pool_size': 2, 'optimizer': 'adam', 'nfilters': 32, 'neurons': [128, 64, 32], 'n_timesteps': 50, 'n_predicted_timesteps': 1, 'n_features': 7, 'metrics': ['accuracy'], 'loss': 'binary_crossentropy', 'epochs': 30, 'dropout': 0.1, 'conv_layer': False, 'conv_act': 'tanh', 'classification': True, 'batch': 64, 'activation': 'relu'},\n",
    "          {'pool_size': 2, 'optimizer': 'adam', 'nfilters': 32, 'neurons': [128, 64, 32], 'n_timesteps': 75, 'n_predicted_timesteps': 1, 'n_features': 7, 'metrics': ['accuracy'], 'loss': 'binary_crossentropy', 'epochs': 30, 'dropout': 0.3, 'conv_layer': False, 'conv_act': 'relu', 'classification': True, 'batch': 32, 'activation': 'relu'}\n",
    "\n",
    "\n",
    "]\n",
    "max_index = scores.index(max(scores))\n",
    "print(max(scores))\n",
    "print(max_index)\n",
    "print(params[max_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msse-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
